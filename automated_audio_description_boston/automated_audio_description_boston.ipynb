{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EqbIXhMpBA9f"
      },
      "source": [
        "# **Install Required Packages**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Uqu_eIDA2Dv"
      },
      "outputs": [],
      "source": [
        "%pip install -q yt-dlp supervision openai numpy opencv-python elevenlabs ffmpeg-python python-dotenv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PhxQmW38BHdu"
      },
      "source": [
        "# **Settings**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BjFnBh-mA3wj"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from dotenv import load_dotenv\n",
        "from pathlib import Path\n",
        "\n",
        "# Get the current working directory (this will be your notebook's directory)\n",
        "cwd = Path(os.getcwd())\n",
        "\n",
        "# Construct the path to the .env file. Adjust the path as per your directory structure.\n",
        "# If your .env file is one directory above your notebook's directory:\n",
        "env_path = cwd.parent / '.env'\n",
        "\n",
        "# Load the .env file\n",
        "load_dotenv(dotenv_path=env_path)\n",
        "\n",
        "OPENAI_API_KEY = os.environ.get('OPENAI_API_KEY')\n",
        "OPENAI_API_URL = \"https://api.openai.com/v1/chat/completions\"\n",
        "\n",
        "VIDEO_URL = 'https://www.youtube.com/watch?v=GW9YZcn8Tik'\n",
        "FRAME_EXTRACTION_FREQUENCY_SECONDS = 4\n",
        "FILES_DIR = \"./files/\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sPK0E7ojBLxo"
      },
      "source": [
        "# **Imports**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TVSHnTQMA8DA"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import cv2\n",
        "import math\n",
        "import base64\n",
        "import requests\n",
        "import subprocess\n",
        "import numpy as np\n",
        "import supervision as sv\n",
        "\n",
        "from shlex import quote\n",
        "from openai import OpenAI\n",
        "from elevenlabs import set_api_key, generate, save"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M44IXizuBQ3T"
      },
      "source": [
        "# **Function Definitions**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def format_video_title(title: str) -> str:\n",
        "    # Regular expressions as constants for clarity\n",
        "    REMOVE_NON_ALPHANUMERIC = r'[^\\w\\s-]'\n",
        "    REPLACE_SPACES_AND_DASHES = r'[-\\s]+'\n",
        "\n",
        "    # Removing non-alphanumeric characters (except spaces and dashes) and lowercasing\n",
        "    sanitized_title = re.sub(REMOVE_NON_ALPHANUMERIC, '', title.lower())\n",
        "    # Replacing spaces and consecutive dashes with a single dash\n",
        "    formatted_title = re.sub(REPLACE_SPACES_AND_DASHES, '-', sanitized_title)\n",
        "\n",
        "    return formatted_title\n",
        "\n",
        "def download_youtube_video(url: str, output_path: str = '.') -> str:\n",
        "    os.makedirs(output_path, exist_ok=True)\n",
        "    safe_url = quote(url)\n",
        "    command_title = f'yt-dlp --get-title {safe_url}'\n",
        "    result_title = subprocess.run(command_title, shell=True, check=True, text=True, capture_output=True)\n",
        "    formatted_title = format_video_title(result_title.stdout.strip())\n",
        "    command_download = f'yt-dlp -o \"{os.path.join(output_path, formatted_title)}.%(ext)s\" -f \"best[ext=mp4]\" {safe_url}'\n",
        "    result_download = subprocess.run(command_download, shell=True, check=True, text=True, capture_output=True)\n",
        "\n",
        "    if result_download.returncode == 0:\n",
        "        return os.path.join(output_path, f\"{formatted_title}.mp4\")\n",
        "    else:\n",
        "        raise Exception(f\"Error in video download: {result_download.stderr}\")\n",
        "\n",
        "def encode_image_to_base64(image: np.ndarray) -> str:\n",
        "    success, buffer = cv2.imencode('.jpg', image)\n",
        "    if not success:\n",
        "        raise ValueError(\"Could not encode image to JPEG format.\")\n",
        "    return base64.b64encode(buffer).decode('utf-8')\n",
        "\n",
        "def compose_payload(images: list, prompt: str) -> dict:\n",
        "    image_content = [{\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/jpeg;base64,{encode_image_to_base64(image=image)}\"}} for image in images]\n",
        "    return {\n",
        "        \"model\": \"gpt-4-vision-preview\",\n",
        "        \"messages\": [{\"role\": \"user\", \"content\": [{\"type\": \"text\", \"text\": prompt}] + image_content}],\n",
        "        \"max_tokens\": 200\n",
        "    }\n",
        "\n",
        "def compose_headers(api_key: str) -> dict:\n",
        "    return {\n",
        "        \"Content-Type\": \"application/json\",\n",
        "        \"Authorization\": f\"Bearer {api_key}\"\n",
        "    }\n",
        "\n",
        "def prompt_image(api_key: str, images: list, prompt: str) -> str:\n",
        "    headers = compose_headers(api_key=api_key)\n",
        "    payload = compose_payload(images=images, prompt=prompt)\n",
        "    response = requests.post(url=OPENAI_API_URL, headers=headers, json=payload).json()\n",
        "    \n",
        "    if 'error' in response:\n",
        "        raise ValueError(response['error']['message'])\n",
        "    \n",
        "    return response['choices'][0]['message']['content']\n",
        "\n",
        "def optimal_grid_size(total_images):\n",
        "    if total_images <= 0:\n",
        "        return 0\n",
        "    grid_size = math.ceil(math.sqrt(total_images))\n",
        "    return grid_size"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "njqKjkJqIKl8"
      },
      "source": [
        "## **Save Video and Extract Frames**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r_jt9KD9DeTM"
      },
      "outputs": [],
      "source": [
        "video_path = download_youtube_video(VIDEO_URL, FILES_DIR)\n",
        "video_info = sv.VideoInfo.from_video_path(video_path=video_path)\n",
        "frame_extraction_frequency = FRAME_EXTRACTION_FREQUENCY_SECONDS * video_info.fps\n",
        "frames = list(sv.get_video_frames_generator(source_path=video_path, stride=frame_extraction_frequency))\n",
        "\n",
        "grid_size = optimal_grid_size(len(frames))\n",
        "sv.plot_images_grid(frames, grid_size=(grid_size, grid_size), size=(16, 16))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ptKL9Q_OBeZ4"
      },
      "source": [
        "# **Generate Description from Frames and LLM API**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LcCtdj-ZBlfY"
      },
      "outputs": [],
      "source": [
        "PROMPT = (\"The uploaded series of images is from a single video sampled every {} seconds. \"\n",
        "          \"Make sure it takes about {} seconds to voice the description of each frame. \"\n",
        "          \"Use exclamation points and capital letters to express excitement if necessary. \"\n",
        "          \"Your responses are spelled out according to how they sound with the Boston Accent. \"\n",
        "          \"You like to use phrases related to Boston. \"\n",
        "          \"Briefly Describe the video as a concise and excited play-by-play caller in the style of Gus Johnson. \"\n",
        "          \"Do not identify the frame within the description.\").format(FRAME_EXTRACTION_FREQUENCY_SECONDS, FRAME_EXTRACTION_FREQUENCY_SECONDS)\n",
        "\n",
        "description = prompt_image(OPENAI_API_KEY, frames, PROMPT)\n",
        "print(description)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E-pjIo0QBoOU"
      },
      "source": [
        "# **Create Audio via Text-to-Speech API**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1x2xGC8LBrH0"
      },
      "outputs": [],
      "source": [
        "XI_API_KEY = os.environ.get('XI_API_KEY')\n",
        "set_api_key(XI_API_KEY)\n",
        "audio = generate(text=description, voice=os.environ.get(\"VOICE_MARKY\"))\n",
        "file_name = os.path.splitext(os.path.basename(video_path))[0]\n",
        "save(audio, f\"{FILES_DIR}{file_name}.mp3\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZOGCyUvUBuK1"
      },
      "source": [
        "# **Combine Audio and Video**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "evsLFlVKAtqU"
      },
      "outputs": [],
      "source": [
        "audio_path = f\"{FILES_DIR}{file_name}.mp3\"\n",
        "output_path = f\"{FILES_DIR}{file_name}_final.mp4\"\n",
        "!/opt/homebrew/bin/ffmpeg -y -i {video_path} -i {audio_path} -c:v copy -c:a aac -strict experimental -map 0:v:0 -map 1:a:0 {output_path}"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
